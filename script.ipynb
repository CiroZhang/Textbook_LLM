{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e58a585b-f867-4078-bc4c-733308396da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import fitz  \n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Read pdf file from pages start to end, outputs all images in image_folder\n",
    "def read(file_path, start, end, image_folder):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        # end = num_pages\n",
    "        if end > num_pages:\n",
    "            print(\"end number outside of total pages\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        if os.path.exists(image_folder):\n",
    "            shutil.rmtree(image_folder)\n",
    "        os.makedirs(image_folder)\n",
    "        \n",
    "        for page_num in range(start, end):\n",
    "\n",
    "            # Text extraction\n",
    "            doc = pdf_reader.pages[page_num]\n",
    "            text = doc.extract_text()\n",
    "            result.append(text)\n",
    "\n",
    "            # Image extraction\n",
    "            doc = fitz.open(file_path)\n",
    "            image_list = doc.get_page_images(page_num)\n",
    "\n",
    "            for i in range(len(image_list)):\n",
    "                img = image_list[i]\n",
    "                xref = img[0]\n",
    "                pix = fitz.Pixmap(doc, xref)\n",
    "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                pix.save(os.path.join(image_folder, \"page_{}_{}.png\".format(page_num+1,i)))\n",
    "            \n",
    "\n",
    "    return result\n",
    "\n",
    "# standard process for textbooks with image_list\n",
    "def process(textbook, start_page, end_page):\n",
    "    def remove_pdf_extension(filename):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            return os.path.splitext(filename)[0]\n",
    "        return filename\n",
    "\n",
    "\n",
    "    book_name = remove_pdf_extension(textbook)\n",
    "    contents = read(textbook, start_page, end_page, \"temp\")\n",
    "    \n",
    "\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    d = {}\n",
    "    for i in range(len(contents)):\n",
    "        # figures = re.findall(r'(Figure \\d+\\.\\d+\\. [\\s\\S]*?)(?=\\n[A-Z0-9]|\\Z)', contents[i])\n",
    "        figures = re.findall(r'(Fig. \\d+\\.\\d+ [\\s\\S]*?)(?=\\n[A-Z0-9]|\\Z)', contents[i])\n",
    "        \n",
    "        figures = [' '.join(s.splitlines()).strip().replace(\"- \", \"\") for s in figures]\n",
    "    \n",
    "        \n",
    "        if len(figures) > 0:\n",
    "            page_number = i + 2\n",
    "    \n",
    "            f = []\n",
    "            \n",
    "            for figure in figures:\n",
    "                # figure_number = match = re.search(r'Figure \\d+\\.\\d+\\.', figure).group(0)\n",
    "                # figure_desc = re.sub(r'Figure \\d+\\.\\d+\\.\\s*', '', figure)\n",
    "\n",
    "                figure_number = match = re.search(r'Fig. \\d+\\.\\d+', figure).group(0)\n",
    "                figure_desc = re.sub(r'Fig. \\d+\\.\\d+\\s*', '', figure)\n",
    "     \n",
    "                data.append([figure_desc, (\"images/\" + figure_number+\"png\").replace(\" \", \"_\")])\n",
    "                \n",
    "                f.append(figure_number)\n",
    "            d[page_number] = f\n",
    "\n",
    "\n",
    "    \n",
    "    if os.path.exists(\"results/\" + book_name  + \"/images\"):\n",
    "        shutil.rmtree(\"results/\" + book_name  + \"/images\")\n",
    "    os.makedirs(\"results/\" + book_name + \"/images\")\n",
    "    \n",
    "    missing = []\n",
    "    for page, figs in d.items():\n",
    "    \n",
    "        for i in range(len(figs)):\n",
    "            if os.path.exists(\"temp/page_{}_{}.png\".format(page,i)):\n",
    "                os.rename(\"temp/page_{}_{}.png\".format(page,i) , \"results/{}/images/{}.png\".format(book_name, figs[i].replace(\" \", \"_\")))\n",
    "            else:\n",
    "                missing.append(figs[i])\n",
    "\n",
    "    shutil.rmtree(\"temp\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"text\", \"file_path\"]\n",
    "\n",
    "    \n",
    "    df.to_json(\"results/\" + book_name + '/output.jsonl', orient='records', lines=True)\n",
    "\n",
    "    with open(\"results/\" + book_name + \"/missing.txt\", \"w\") as file:\n",
    "        for item in missing:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def process_no_list(textbook, start_page, end_page):\n",
    "    def extract_images_from_page(image_path, output_folder):\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "    \n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Could not read the image file: {image_path}\")\n",
    "            return\n",
    "    \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                       cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        \n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        image_count = 0\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "        \n",
    "            if w > 100 and h > 100:\n",
    "                cropped_image = img[y:y+h, x:x+w]\n",
    "    \n",
    "                # Save the cropped image\n",
    "                image_filename = os.path.join(output_folder, f\"extracted_image_{image_count}.png\")\n",
    "                cv2.imwrite(image_filename, cropped_image)\n",
    "                image_count += 1\n",
    "    \n",
    "        return image_count\n",
    "    \n",
    "    def process_directory(input_directory, output_directory):\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                file_path = os.path.join(input_directory, filename)\n",
    "                specific_output_folder = os.path.join(output_directory, os.path.splitext(filename)[0])\n",
    "                os.makedirs(specific_output_folder, exist_ok=True)\n",
    "                number_of_images = extract_images_from_page(file_path, specific_output_folder)\n",
    "\n",
    "    def remove_pdf_extension(filename):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            return os.path.splitext(filename)[0]\n",
    "        return filename\n",
    "\n",
    "\n",
    "    book_name = remove_pdf_extension(textbook)\n",
    "    contents = read(textbook, start_page, end_page, \"temp\")\n",
    "    process_directory(\"temp\", \"results/\" + book_name)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd0d915e-1ff1-4201-a0cd-96ebe8287cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textbook = \"Sternberg.pdf\" <-- need fix missing\n",
    "textbook = \"Histology.pdf\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "process_no_list(textbook, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3ab86-a2ae-4822-8eb3-a043faefc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "pdf_files = glob.glob(os.path.join(current_directory, \"*.pdf\"))\n",
    "textbooks = [os.path.basename(pdf) for pdf in pdf_files]\n",
    "\n",
    "failed_textbooks = []\n",
    "\n",
    "for textbook in textbooks:\n",
    "    try:\n",
    "        print(f\"Processing {textbook}...\")\n",
    "        process(textbook, 1, 170)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {textbook}: {e}\")\n",
    "        failed_textbooks.append(textbook)\n",
    "\n",
    "if failed_textbooks:\n",
    "    print(\"\\nThe following textbooks could not be processed:\")\n",
    "    for failed_textbook in failed_textbooks:\n",
    "        print(failed_textbook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c417fdd-3117-40dc-ac6b-701cc7b95177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14870f-09ec-4565-a6cf-33627cd59c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4793c9f-e6fc-475a-963a-2a2adc2433dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
